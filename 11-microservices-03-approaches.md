# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
Моё предложение использовать GitLab
- облачная система;  
Есть возможность развернуть в облаке
- система контроля версий Git;  
Присутствует  
- репозиторий на каждый сервис;  
Реализовано в системе контроля версий Gitlab  
- запуск сборки по событию из системы контроля версий;  
реализовано в CI системе GitLab  
- запуск сборки по кнопке с указанием параметров;
реализовано в CI системе GitLab
- возможность привязать настройки к каждой сборке;
реализовано в CI системе GitLab
- возможность создания шаблонов для различных конфигураций сборок;
реализовано в CI системе GitLab. pipeline template и job templatee  
- возможность безопасного хранения секретных данных (пароли, ключи доступа);  
реализовано в CI системе GitLab. С помощью masked variables + шифрование переменных и хранение хеша в переменных. Дешифровка при вызове.  
- несколько конфигураций для сборки из одного репозитория;  
реализовано в CI системе GitLab с помощью директивы include можно мерджить разные gitlab-ci.yaml  
- кастомные шаги при сборке;  
реализовано в CI системе GitLab с помощью steps  
- собственные докер-образы для сборки проектов;  
Можно использовать Docker executor на раннере для сборки собственных образов и запуска контейнеров из него.  
- возможность развернуть агентов сборки на собственных серверах;  
GitLab подразумевает такую возможность  
- возможность параллельного запуска нескольких сборок;  
Можно запускать джобы в, которых выполняются сборки параллельно с помощью директивы parallel:количество параллельных джобов  
- возможность параллельного запуска тестов.  
аналогичко в параллельных джобах  
Обоснуйте свой выбор.

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.  
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.  
Предлагаю использовать ELK стек elasticSearch logstash kibana  
Решение должно соответствовать следующим требованиям:  
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;  
С помощью filebeat + logstash в elastic  
- минимальные требования к приложениям, сбор логов из stdout;  
filebeat позволяет забирать сообщения из стандартного вывода  
Пример конфига:  
```yml
- type: container
  stream: stdout
  paths:
    - "/var/log/containers/*.log"
```
- гарантированная доставка логов до центрального хранилища;  
Не нашел информации о том, как выполнять гарантированную доставку логов. Могу предположить, что гарантия доставки может быть обеспечена избыточностью в кластере ELK путем шардирования.  
- обеспечение поиска и фильтрации по записям логов;  
Kibana обеспечивает данный функционал.  
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;  
Kibana обеспечивает данный функционал.  
- возможность дать ссылку на сохранённый поиск по записям логов.  
Возможно сохранить в CSV или permalimk  
Обоснуйте свой выбор.

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.
  
 Предлагаю использовать стек grafana alert manager prometheus, а из контейнеров метрики собирать cAdvisor  
   
Решение должно соответствовать следующим требованиям:  
- сбор метрик со всех хостов, обслуживающих систему;  
ВМ + физические хосты метрики собираем Node exporter, контейнеры cadvisor  
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;  
node exporter  
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;  
cadvisor  
- сбор метрик, специфичных для каждого сервиса;  
Используем библиотеку prometheus_flask_exporter  
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;  
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.  
grafana позволяет  
Обоснуйте свой выбор.

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
